{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook represents my personal notes following the tutorial \"Recurrent Neural Netowrks by Emaxple in Python\"from Medium. My hope is to use this template to deploy my own text generators based on the following architecture. Much of the following is a direct pull from the blog: https://towardsdatascience.com/recurrent-neural-networks-by-example-in-python-ffd204f99470"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "1. Convert abstracts from list of strings into list of lists of integers (sequences)\n",
    "2. Create feature and labels from sequences\n",
    "3. Build LSTM model with Embedding, LSTM, and Dense Layers\n",
    "4. Load in pre-trained embeddings\n",
    "5. Train model to predict next work in sequence\n",
    "6. Make predictions by passing in staarting sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nicholasbeaudoin/Desktop/Projects/Patent-Generator\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('data/abstracts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Electronic neural network for solving \"\"trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D convolutional neural networks for automatic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accelerated training apparatus for back propag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accelerating learning in neural networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accelerator for deep neural networks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        patent_title\n",
       "0  \"Electronic neural network for solving \"\"trave...\n",
       "1  3D convolutional neural networks for automatic...\n",
       "2  Accelerated training apparatus for back propag...\n",
       "3           Accelerating learning in neural networks\n",
       "4               Accelerator for deep neural networks"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstracts is a list of strings\n",
    "abstracts = list(df.patent_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Electronic neural network for solving \"\"traveling salesman\"\" and similar global optimization problems\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Abstracts is a list of strings\n",
    "abstracts[0][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer object\n",
    "tokenizer = Tokenizer(num_words=None,\n",
    "                    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_{|}~\\t\\n',\n",
    "                    lower = True,\n",
    "                    split = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the tokenizer to the texts\n",
    "tokenizer.fit_on_texts(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of strings into list of lists of integers\n",
    "sequences = tokenizer.texts_to_sequences(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[69, 1, 9, 4, 584, 936, 937, 2, 585, 321, 49, 938]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First abstract from above example\n",
    "sequences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the idx_word attribute of the trained tokenizer to figure out what each of these integers means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'electronic neural network for solving traveling salesman and similar global optimization problems'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping of indexes to words\n",
    "idx_word = tokenizer.index_word\n",
    "\n",
    "' '.join(idx_word[w] for w in sequences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer has taken care of all the text cleaning for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't remove punctuation or uppercase\n",
    "tokenizer = Tokenizer(num_words=None, \n",
    "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "                     lower = False, \n",
    "                     split = ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training our own embeddings, we donâ€™t have to worry about this because the model will learn different representations for lower and upper case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
